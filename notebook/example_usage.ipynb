{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# disRNN Result Access — Example Usage\n",
    "\n",
    "This notebook demonstrates how to use `aind-disrnn-result-access` to query\n",
    "W&B run metadata and download training artifacts.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Install the package: `uv sync` or `pip install -e .`\n",
    "- Set WANDB_API_KEY environment variable (or run `wandb login`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoload notebook extension for improved usability\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.Api()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "from aind_disrnn_result_access import WandbClient\n",
    "\n",
    "client = WandbClient()  # defaults to entity=\"AIND-disRNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Available Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available projects:\n",
      "  - alex_test\n",
      "  - pochen_mice_multisubject\n",
      "  - rachel_mice_grurnn_parascan\n",
      "  - debug-synthetic_task_trained_rnn\n",
      "  - synthetic_task_trained_rnn\n",
      "  - han_synthetic_rl_disrnn\n",
      "  - han_mice_disrnn\n",
      "  - han_cpu_gpu_test\n",
      "  - han_mice_disrnn_bottleneck_overtime\n",
      "  - han_mice_disrnn_parascan\n",
      "  - test\n",
      "  - han-test\n"
     ]
    }
   ],
   "source": [
    "projects = client.get_projects()\n",
    "print(\"Available projects:\")\n",
    "for p in projects:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Browse Runs\n",
    "\n",
    "List runs in a project. You can filter and sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a project (change this to whichever project you want to explore)\n",
    "PROJECT = \"han_cpu_gpu_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73 runs in 'han_cpu_gpu_test'\n",
      "  [0q45cmry] 1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 — state=finished\n",
      "  [lzij3ybo] 1gpu4cpu64G_bs256_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 — state=finished\n",
      "  [0ec4vqq6] 1gpu4cpu64G_bs1024_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 — state=finished\n",
      "  [cju5e411] 1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 — state=finished\n",
      "  [1mqgpxrq] 1gpu4cpu64G_bs128_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 — state=finished\n"
     ]
    }
   ],
   "source": [
    "runs = client.get_runs(project=PROJECT)\n",
    "print(f\"Found {len(runs)} runs in '{PROJECT}'\")\n",
    "for run in runs[:5]:  # show first 5\n",
    "    print(f\"  [{run.id}] {run.name} — state={run.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter runs\n",
    "\n",
    "Use [MongoDB-style queries](https://docs.wandb.ai/guides/runs/filter-runs) to filter runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 finished runs\n"
     ]
    }
   ],
   "source": [
    "finished_runs = client.get_runs(\n",
    "    project=PROJECT,\n",
    "    filters={\"state\": \"finished\"},\n",
    ")\n",
    "print(f\"Found {len(finished_runs)} finished runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get runs as DataFrame\n",
    "\n",
    "For easier analysis, you can get all runs as a pandas DataFrame (similar to W&B web UI table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (73, 85)\n",
      "\n",
      "Columns (85 total):\n",
      "  Basic: ['id', 'name', 'state', 'created_at', 'url', 'tags']\n",
      "  Config: ['config.data.seed', 'config.data.task.mean', 'config.data.task.seed', 'config.data.task.type', 'config.data.task.p_max']...\n",
      "  Summary: ['summary._runtime', 'summary._step', 'summary._timestamp', 'summary._wandb', 'summary.elapsed_seconds']...\n",
      "\n",
      "First 5 runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>summary.likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0q45cmry</td>\n",
       "      <td>1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...</td>\n",
       "      <td>finished</td>\n",
       "      <td>0.833104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lzij3ybo</td>\n",
       "      <td>1gpu4cpu64G_bs256_wu500_5_3_4_0_beta0.001_lr0....</td>\n",
       "      <td>finished</td>\n",
       "      <td>0.832780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ec4vqq6</td>\n",
       "      <td>1gpu4cpu64G_bs1024_wu500_5_3_4_0_beta0.001_lr0...</td>\n",
       "      <td>finished</td>\n",
       "      <td>0.832802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cju5e411</td>\n",
       "      <td>1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...</td>\n",
       "      <td>finished</td>\n",
       "      <td>0.832756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1mqgpxrq</td>\n",
       "      <td>1gpu4cpu64G_bs128_wu500_5_3_4_0_beta0.001_lr0....</td>\n",
       "      <td>finished</td>\n",
       "      <td>0.831901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               name     state  \\\n",
       "0  0q45cmry  1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...  finished   \n",
       "1  lzij3ybo  1gpu4cpu64G_bs256_wu500_5_3_4_0_beta0.001_lr0....  finished   \n",
       "2  0ec4vqq6  1gpu4cpu64G_bs1024_wu500_5_3_4_0_beta0.001_lr0...  finished   \n",
       "3  cju5e411  1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...  finished   \n",
       "4  1mqgpxrq  1gpu4cpu64G_bs128_wu500_5_3_4_0_beta0.001_lr0....  finished   \n",
       "\n",
       "   summary.likelihood  \n",
       "0            0.833104  \n",
       "1            0.832780  \n",
       "2            0.832802  \n",
       "3            0.832756  \n",
       "4            0.831901  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get runs as DataFrame with flattened config and summary\n",
    "df = client.get_runs_dataframe(project=PROJECT)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns ({len(df.columns)} total):\")\n",
    "print(f\"  Basic: {[c for c in df.columns if not c.startswith(('config.', 'summary.'))]}\")\n",
    "print(f\"  Config: {[c for c in df.columns if c.startswith('config.')][:5]}...\")\n",
    "print(f\"  Summary: {[c for c in df.columns if c.startswith('summary.')][:5]}...\")\n",
    "\n",
    "# Display first few rows with selected columns\n",
    "display_cols = ['id', 'name', 'state', 'summary.likelihood', 'summary.final.val_loss']\n",
    "available_cols = [c for c in display_cols if c in df.columns]\n",
    "print(f\"\\nFirst 5 runs:\")\n",
    "df[available_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame analysis examples\n",
    "\n",
    "The DataFrame makes it easy to filter and analyze runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-performing runs (likelihood > 0.8): 43\n",
      "         id                                               name  \\\n",
      "0  0q45cmry  1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...   \n",
      "1  lzij3ybo  1gpu4cpu64G_bs256_wu500_5_3_4_0_beta0.001_lr0....   \n",
      "2  0ec4vqq6  1gpu4cpu64G_bs1024_wu500_5_3_4_0_beta0.001_lr0...   \n",
      "3  cju5e411  1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0...   \n",
      "4  1mqgpxrq  1gpu4cpu64G_bs128_wu500_5_3_4_0_beta0.001_lr0....   \n",
      "\n",
      "   summary.likelihood  \n",
      "0            0.833104  \n",
      "1            0.832780  \n",
      "2            0.832802  \n",
      "3            0.832756  \n",
      "4            0.831901  \n",
      "\n",
      "Runs by batch size:\n",
      "config.data.batch_size\n",
      "128.0      8\n",
      "256.0     10\n",
      "512.0     10\n",
      "1024.0    10\n",
      "2048.0     8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Filter runs by performance\n",
    "if 'summary.likelihood' in df.columns:\n",
    "    high_performers = df[df['summary.likelihood'] > 0.8]\n",
    "    print(f\"High-performing runs (likelihood > 0.8): {len(high_performers)}\")\n",
    "    print(high_performers[['id', 'name', 'summary.likelihood']].head())\n",
    "\n",
    "# Example: Sort by validation loss\n",
    "if 'summary.final.val_loss' in df.columns:\n",
    "    best_runs = df.sort_values('summary.final.val_loss').head(3)\n",
    "    print(f\"\\nTop 3 runs by validation loss:\")\n",
    "    print(best_runs[['id', 'name', 'summary.final.val_loss']])\n",
    "\n",
    "# Example: Group by config parameter\n",
    "if 'config.data.batch_size' in df.columns:\n",
    "    print(f\"\\nRuns by batch size:\")\n",
    "    print(df.groupby('config.data.batch_size').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect a Single Run\n",
    "\n",
    "Get detailed metadata for a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1gpu4cpu64G_bs2048_wu500_5_3_4_0_beta0.001_lr0.005_grad_clip1 (0q45cmry)\n",
      "State: finished\n",
      "Tags: ['batch_size', 'cpu', 'disrnn', 'synthetic']\n",
      "Created: 2026-02-06T22:20:05Z\n",
      "URL: https://wandb.ai/AIND-disRNN/han_cpu_gpu_test/runs/0q45cmry\n"
     ]
    }
   ],
   "source": [
    "# Use the first run from our list (or replace with a known run ID)\n",
    "if runs:\n",
    "    run = client.get_run(runs[0].id, project=PROJECT)\n",
    "    print(f\"Run: {run.name} ({run.id})\")\n",
    "    print(f\"State: {run.state}\")\n",
    "    print(f\"Tags: {run.tags}\")\n",
    "    print(f\"Created: {run.created_at}\")\n",
    "    print(f\"URL: {run.url}\")\n",
    "else:\n",
    "    print(\"No runs found — adjust PROJECT above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run config (training hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  data: {'seed': 0, 'task': {'mean': 0, 'seed': 0, 'type': 'random_walk', 'p_max': 1, 'p_min': 0, 'sigma': 0.15, 'num_trials': 500, 'reward_baiting': True}, 'type': 'synthetic', 'agent': {'seed': 0, 'type': 'ForagerQLearning', 'agent_class': 'ForagerQLearning', 'agent_kwargs': {'choice_kernel': 'none', 'action_selection': 'softmax', 'number_of_forget_rate': 0, 'number_of_learning_rate': 1}, 'agent_params': {'learn_rate': 0.5, 'softmax_inverse_temperature': 10}, 'loader_target': 'data_loaders.synthetic.SyntheticCognitiveAgents', 'agent_params_session_var': {'biasL': {'max': 3, 'min': -3, 'type': 'uniform'}}}, '_target_': 'data_loaders.synthetic.SyntheticCognitiveAgents', 'batch_mode': 'random', 'batch_size': 2048, 'num_trials': 500, 'eval_every_n': 2, 'num_sessions': 1000, 'run_name_component': 'synthetic_ForagerQLearning_random_walk'}\n",
      "  model: {'seed': 0, 'type': 'disrnn', '_target_': 'model_trainers.disrnn_trainer.DisrnnTrainer', 'training': {'lr': 0.005, 'loss': 'penalized_categorical', 'n_steps': 5000, 'loss_param': 1, 'max_grad_norm': 1, 'n_warmup_steps': 500}, 'penalties': {'beta': 0.001, 'latent_penalty': 0.001, 'update_net_obs_penalty': 0.001, 'choice_net_latent_penalty': 0.001, 'update_net_latent_penalty': 0.001}, 'architecture': {'activation': 'leaky_relu', 'latent_size': 5, 'choice_net_n_layers': 0, 'update_net_n_layers': 3, 'choice_net_n_units_per_layer': 4, 'update_net_n_units_per_layer': 5}, 'run_name_component': 'disrnn_beta0.001_lr0.005'}\n",
      "  CO_COMPUTATION_ID: f7be5d66-7889-4223-9d2b-1b9b72c0d874\n"
     ]
    }
   ],
   "source": [
    "if runs:\n",
    "    print(\"Config:\")\n",
    "    for key, value in run.config.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run summary (final metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary metrics:\n",
      "  _runtime: 4008\n",
      "  _step: 5504\n",
      "  _timestamp: 1770420397.23481\n",
      "  _wandb: {'runtime': 4008}\n",
      "  elapsed_seconds: 3581.5833921432495\n",
      "  fig/bottlenecks: {'_type': 'image-file', 'format': 'png', 'height': 500, 'path': 'media/images/fig/bottlenecks_5500_c0f37d17c21160d7cd00.png', 'sha256': 'c0f37d17c21160d7cd002c18c7e20e0731515207728393dfcabb0d13f0b6ddf7', 'size': 60570, 'width': 1500}\n",
      "  fig/choice_rule: {'_type': 'image-file', 'format': 'png', 'height': 480, 'path': 'media/images/fig/choice_rule_5501_207bb5ad61bd2fec6d51.png', 'sha256': '207bb5ad61bd2fec6d51f34a354c4984492f6d79de1c6936e536f3c8e6aaa350', 'size': 25705, 'width': 640}\n",
      "  fig/update_rule_0: {'_type': 'image-file', 'format': 'png', 'height': 550, 'path': 'media/images/fig/update_rule_0_5502_f8aee37072a6f5891b2a.png', 'sha256': 'f8aee37072a6f5891b2a12fab0d017bb7e1c91657bd6ab8583de429bac8673d7', 'size': 127483, 'width': 1800}\n",
      "  fig/update_rule_1: {'_type': 'image-file', 'format': 'png', 'height': 550, 'path': 'media/images/fig/update_rule_1_5503_0627c31b235a82819dbe.png', 'sha256': '0627c31b235a82819dbe69ce282857d04929c239be28fcbb79a40912d4e557d1', 'size': 74415, 'width': 1400}\n",
      "  fig/update_rule_2: {'_type': 'image-file', 'format': 'png', 'height': 550, 'path': 'media/images/fig/update_rule_2_5504_66b4d913056b8a1a8d55.png', 'sha256': '66b4d913056b8a1a8d550f4d5777dcdc1498507e6b97ccc6c1f8b80799997d9e', 'size': 27847, 'width': 800}\n",
      "  fig/validation_loss_curve: {'_type': 'image-file', 'format': 'png', 'height': 480, 'path': 'media/images/fig/validation_loss_curve_5499_c9d3f2376ae24085d5c7.png', 'sha256': 'c9d3f2376ae24085d5c7f90783e0ddf5d8693aab2bb91e728e2f1e72d692ba94', 'size': 29288, 'width': 640}\n",
      "  fig/warmup_loss_curve: {'_type': 'image-file', 'format': 'png', 'height': 480, 'path': 'media/images/fig/warmup_loss_curve_499_93d441e5057670d97faa.png', 'sha256': '93d441e5057670d97faae813ee0d09e8b485af5704ac76c8a4d17185d7c2a2ca', 'size': 31757, 'width': 640}\n",
      "  final/train_loss: 0.21905161440372467\n",
      "  final/val_loss: 0.21539299190044403\n",
      "  groundtruth_likelihood: 0.8533333539962769\n",
      "  likelihood: 0.8331044316291809\n",
      "  likelihood_relative_to_groundtruth: 0.97629423217508\n",
      "  train/loss: 0.21905161440372467\n",
      "  valid/loss: 0.21539299190044403\n",
      "  warmup_seconds: 340.0133674144745\n"
     ]
    }
   ],
   "source": [
    "if runs:\n",
    "    print(\"Summary metrics:\")\n",
    "    for key, value in run.summary.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Get Time-Series History\n\nGet training metrics over time (e.g., loss curves) for a run.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get time-series history for the run\nif runs:\n    history = client.get_run_history(runs[0].id, project=PROJECT)\n    print(f\"History shape: {history.shape}\")\n    print(f\"Columns: {list(history.columns)[:10]}...\")\n    \n    # Display first few rows\n    display_cols = [\"_step\", \"train/loss\", \"valid/loss\"]\n    available_cols = [c for c in display_cols if c in history.columns]\n    print(f\"\\nFirst few rows of training history:\")\n    print(history[available_cols].head())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Download Artifacts\n\nDownload training output artifacts (model parameters, plots, CSVs) for a run.\n\n**Default behavior:** Downloads to `/root/capsule/results/downloaded_artifacts/<artifact_name>/`\n\nNote: Artifact names typically contain the run_id (e.g., `disrnn-output-0q45cmry`)."
  },
  {
   "cell_type": "code",
   "source": "if runs:\n    artifacts = client.download_artifact(\n        runs[0].id,\n        project=PROJECT,\n    )\n    for art in artifacts:\n        print(f\"Artifact: {art.name} (type={art.type}, version={art.version})\")\n        print(f\"  Downloaded to: {art.download_path}\")\n        print(f\"  Files: {art.files}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Download specific files only\n\nYou can download only specific files instead of the entire artifact:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if runs:\n    # Download only params.json\n    artifacts = client.download_artifact(\n        runs[0].id,\n        project=PROJECT,\n        files=[\"params.json\"]\n    )\n    print(f\"Downloaded {len(artifacts[0].files)} file(s): {artifacts[0].files}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. Explore Downloaded Files\n\nAfter downloading, artifacts are available as local files in `/root/capsule/results/downloaded_artifacts/`."
  },
  {
   "cell_type": "code",
   "source": "import json\nfrom pathlib import Path\n\nif runs:\n    # Download all files using default settings\n    artifacts = client.download_artifact(runs[0].id, project=PROJECT)\n    artifact_dir = artifacts[0].download_path\n    \n    print(f\"Contents of {artifact_dir}:\")\n    for f in sorted(Path(artifact_dir).rglob(\"*\")):\n        if f.is_file():\n            print(f\"  {f.name}\")\n\n    # Example: load params.json if it exists\n    params_file = artifact_dir / \"params.json\"\n    if params_file.exists():\n        with open(params_file) as fh:\n            params = json.load(fh)\n        print(f\"\\nLoaded params.json with {len(params)} keys\")\n        for k, v in list(params.items())[:5]:\n            print(f\"  {k}: {v}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}